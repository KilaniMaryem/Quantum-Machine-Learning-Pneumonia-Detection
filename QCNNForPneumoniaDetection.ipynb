{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjDZM44kmvQm",
        "outputId": "35c6764b-b1f7-4fe5-c757-c54ec229d20c"
      },
      "outputs": [],
      "source": [
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_9PHF8OoztX",
        "outputId": "df7862f6-26ab-49e7-fa74-e8ee8eea227e"
      },
      "outputs": [],
      "source": [
        "!pip3 install tensorflow==2.15.0\n",
        "!pip3 install -U tensorflow-quantum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L5oRzYSoJZC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import collections\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFVMwRSlsdIM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-ulbHwIsex6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2YE0t--sffW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBu1UsnrJTy"
      },
      "source": [
        "# 1. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxI2aHLbnJsP"
      },
      "source": [
        "You can find the original dataset here: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKtDSiy9nY7t"
      },
      "source": [
        "I already resized the images to (200,200) and uploded them into my drive, so I'll be importing them from there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Qgj02rnudD",
        "outputId": "e60a38f8-6c7c-4ef3-9f86-56b8bf0b1eed"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZmk7FV-stLG"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/resized_chest_xray/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgS2jDl-vGLW",
        "outputId": "83e0d7d4-fec2-4b49-aca3-37e8c8d1f3d4"
      },
      "outputs": [],
      "source": [
        "folders=os.listdir(data_dir)\n",
        "folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il_XrFiwov_H",
        "outputId": "0a8248fb-4133-4065-87bc-406c94837170"
      },
      "outputs": [],
      "source": [
        "print( len(os.listdir(data_dir+'/PNEUMONIA')) ) #3875\n",
        "print( len(os.listdir(data_dir+'/NORMAL')) ) #1341"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om4n6EZQth5b"
      },
      "outputs": [],
      "source": [
        "filepaths = []\n",
        "labels = []\n",
        "for folder in folders:\n",
        "    for filename in os.listdir(os.path.join(data_dir,folder)):\n",
        "      filepath=os.path.join(data_dir,folder,filename)\n",
        "      filepaths.append(filepath)\n",
        "      labels.append(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-Cfue554qJ0"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/resized_chest_xray/train'\n",
        "val_dir = '/content/drive/MyDrive/resized_chest_xray/val'\n",
        "test_dir = '/content/drive/MyDrive/resized_chest_xray/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nb5OSkA5hTC"
      },
      "outputs": [],
      "source": [
        "def get_paths(dir,class_dir):\n",
        "  return [os.path.join(dir,class_dir,fn) for fn in os.listdir(os.path.join(dir,class_dir))]\n",
        "\n",
        "\n",
        "train_dir_pneumonia=get_paths(train_dir,'PNEUMONIA')\n",
        "train_dir_normal=get_paths(train_dir,'NORMAL')\n",
        "\n",
        "\n",
        "val_dir_pneumonia=get_paths(val_dir,'PNEUMONIA')\n",
        "val_dir_normal=get_paths(val_dir,'NORMAL')\n",
        "\n",
        "test_dir_pneumonia=get_paths(test_dir,'PNEUMONIA')\n",
        "test_dir_normal=get_paths(test_dir,'NORMAL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cwlx1uAI4zDd"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def plot_images(dir):\n",
        "  plt.figure(figsize=(20, 20))\n",
        "  for i in range(4):\n",
        "      plt.subplot(4, 4, i + 1)\n",
        "      image = Image.open(dir[i])\n",
        "      image_array = np.array(image) / 255.0\n",
        "      plt.imshow(image_array,cmap='gray')\n",
        "      plt.title(i, fontsize= 12)\n",
        "      plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "8a4EjCHHAHBN",
        "outputId": "6cc61020-413c-410e-9145-3ac8f1d1a061"
      },
      "outputs": [],
      "source": [
        "plot_images(train_dir_pneumonia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "FcAauDDi_Ql1",
        "outputId": "0a7a40b4-1b30-4bc9-ad79-682afa715ba2"
      },
      "outputs": [],
      "source": [
        "plot_images(train_dir_normal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVlA-s4XqukL"
      },
      "source": [
        "Pneumonia will be class 1 and Normal will be class 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFdOj8llqG-i"
      },
      "outputs": [],
      "source": [
        "def define_x_y(dir):\n",
        "    x = []\n",
        "    y = []\n",
        "    for cl in os.listdir(dir):\n",
        "        for img in get_paths(dir, cl):\n",
        "            x.append(cv2.imread(img, cv2.IMREAD_GRAYSCALE))\n",
        "            if cl == 'PNEUMONIA':\n",
        "                y.append(1)\n",
        "            else:\n",
        "                y.append(0)\n",
        "    x=np.array(x)\n",
        "    y = np.array(y)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNs_Ysh1wT1h"
      },
      "outputs": [],
      "source": [
        "x_train,y_train=define_x_y(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibsb2mlCrf1k"
      },
      "outputs": [],
      "source": [
        "x_val,y_val=define_x_y(val_dir)\n",
        "x_test,y_test=define_x_y(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvtRD0JvvVXL",
        "outputId": "0bbff5ad-a742-4ae3-88a5-209251784363"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glMM4m3wxsQs"
      },
      "outputs": [],
      "source": [
        "img_size=200\n",
        "x_train = x_train.reshape(-1,img_size,img_size,1)\n",
        "x_val = x_val.reshape(-1,img_size,img_size,1)\n",
        "x_test = x_test.reshape(-1,img_size,img_size,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NkWGuZvyRUT"
      },
      "outputs": [],
      "source": [
        "x_train= tf.cast(x_train, tf.float32)\n",
        "x_val=tf.cast(x_val, tf.float32)\n",
        "x_test=tf.cast(x_test, tf.float32)\n",
        "\n",
        "x_train = tf.image.resize(x_train[:], (10,10)).numpy()\n",
        "x_val = tf.image.resize(x_val[:], (10,10)).numpy()\n",
        "x_test = tf.image.resize(x_test[:], (10,10)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6iFiHyIzaAO"
      },
      "source": [
        "# 2. CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-oJ5P9QymdV"
      },
      "outputs": [],
      "source": [
        "cnn_model = Sequential()\n",
        "\n",
        "cnn_model.add(Conv2D(8, (2, 2), activation='relu', input_shape=(10, 10, 1)))\n",
        "\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(32, activation='relu'))\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpOlaKmdzwqF",
        "outputId": "31394a5d-f948-4d69-8e1e-6c432d515fb8"
      },
      "outputs": [],
      "source": [
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y00vy_4kyu4z",
        "outputId": "5df7dac5-c458-49dd-88fa-54702c5b900b"
      },
      "outputs": [],
      "source": [
        "cnn_model.compile(optimizer=tf.optimizers.Adam(),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "cnn_history = cnn_model.fit(x_train, y_train, steps_per_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=10, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2beT6yEy7Qtr",
        "outputId": "54f110d6-4d85-4f29-e9a1-e1d4150799e5"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = cnn_model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA-ey2gpzxRH"
      },
      "source": [
        "# 3. QCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64N1Lu7nz8Yo"
      },
      "outputs": [],
      "source": [
        "class QConv(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_size, depth, activation=None, name=None, kernel_regularizer=None, **kwangs):\n",
        "        super(QConv, self).__init__(name=name, **kwangs)\n",
        "        self.filter_size = filter_size\n",
        "        self.depth = depth\n",
        "        self.learning_params = []\n",
        "        self.QCNN_layer_gen()\n",
        "        self.activation = tf.keras.layers.Activation(activation)\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "\n",
        "    def _next_qubit_set(self, original_size, next_size, qubits):\n",
        "        step = original_size // next_size\n",
        "        qubit_list = []\n",
        "        for i in range(0, original_size, step):\n",
        "            for j in range(0, original_size, step):\n",
        "                qubit_list.append(qubits[original_size*i + j])\n",
        "        return qubit_list\n",
        "\n",
        "    def _get_new_param(self):\n",
        "        \"\"\"\n",
        "        return new learnable parameter\n",
        "        all returned parameter saved in self.learning_params\n",
        "        \"\"\"\n",
        "        new_param = sympy.symbols(\"p\"+str(len(self.learning_params)))\n",
        "        self.learning_params.append(new_param)\n",
        "        return new_param\n",
        "\n",
        "    def _QConv(self, step, target, qubits):\n",
        "        \"\"\"\n",
        "        apply learnable gates each quantum convolutional layer level\n",
        "        \"\"\"\n",
        "        yield cirq.CZPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n",
        "        yield cirq.CXPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n",
        "\n",
        "    def QCNN_layer_gen(self):\n",
        "        \"\"\"\n",
        "        make quantum convolutional layer in QConv layer\n",
        "        \"\"\"\n",
        "        pixels = self.filter_size**2\n",
        "        if np.log2(pixels) % 1 != 0:\n",
        "            raise NotImplementedError(\"filter size: 2^n only available\")\n",
        "        cirq_qubits = cirq.GridQubit.rect(self.filter_size, self.filter_size)\n",
        "        input_circuit = cirq.Circuit()\n",
        "        input_params = [sympy.symbols('a%d' %i) for i in range(pixels)]\n",
        "        for i, qubit in enumerate(cirq_qubits):\n",
        "            input_circuit.append(cirq.rx(np.pi*input_params[i])(qubit))\n",
        "        \n",
        "        QCNN_circuit = cirq.Circuit()\n",
        "        step_size = [2**i for i in range(np.log2(pixels).astype(np.int32))]\n",
        "        for step in step_size:\n",
        "            for target in range(0, pixels, 2*step):\n",
        "                QCNN_circuit.append(self._QConv(step, target, cirq_qubits))\n",
        "       \n",
        "        full_circuit = cirq.Circuit()\n",
        "        full_circuit.append(input_circuit)\n",
        "        full_circuit.append(QCNN_circuit)\n",
        "        self.circuit = full_circuit \n",
        "        self.params = input_params + self.learning_params\n",
        "        self.op = cirq.Z(cirq_qubits[0])\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.width = input_shape[1]\n",
        "        self.height = input_shape[2]\n",
        "        self.channel = input_shape[3]\n",
        "        self.num_x = self.width - self.filter_size + 1\n",
        "        self.num_y = self.height - self.filter_size + 1\n",
        "\n",
        "        self.kernel = self.add_weight(name=\"kenel\",\n",
        "                                      shape=[self.depth,\n",
        "                                             self.channel,\n",
        "                                             len(self.learning_params)],\n",
        "                                     initializer=tf.keras.initializers.glorot_normal(),\n",
        "                                     regularizer=self.kernel_regularizer)\n",
        "        self.circuit_tensor = tfq.convert_to_tensor([self.circuit] * self.num_x * self.num_y * self.channel)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        stack_set = None\n",
        "        for i in range(self.num_x):\n",
        "            for j in range(self.num_y):\n",
        "                slice_part = tf.slice(inputs, [0, i, j, 0], [-1, self.filter_size, self.filter_size, -1])\n",
        "                slice_part = tf.reshape(slice_part, shape=[-1, 1, self.filter_size, self.filter_size, self.channel])\n",
        "                if stack_set == None:\n",
        "                    stack_set = slice_part\n",
        "                else:\n",
        "                    stack_set = tf.concat([stack_set, slice_part], 1)\n",
        "        stack_set = tf.transpose(stack_set, perm=[0, 1, 4, 2, 3])\n",
        "        stack_set = tf.reshape(stack_set, shape=[-1, self.filter_size**2])\n",
        "\n",
        "        circuit_inputs = tf.tile([self.circuit_tensor], [tf.shape(inputs)[0], 1])\n",
        "        circuit_inputs = tf.reshape(circuit_inputs, shape=[-1])\n",
        "        tf.fill([tf.shape(inputs)[0]*self.num_x*self.num_y, 1], 1)\n",
        "        outputs = []\n",
        "        for i in range(self.depth):\n",
        "            controller = tf.tile(self.kernel[i], [tf.shape(inputs)[0]*self.num_x*self.num_y, 1])\n",
        "            outputs.append(self.single_depth_QCNN(stack_set, controller, circuit_inputs))\n",
        "    \n",
        "\n",
        "        output_tensor = tf.stack(outputs, axis=3)\n",
        "        output_tensor = tf.math.acos(tf.clip_by_value(output_tensor, -1+1e-5, 1-1e-5)) / np.pi\n",
        "        return self.activation(output_tensor)\n",
        "\n",
        "    def single_depth_QCNN(self, input_data, controller, circuit_inputs):\n",
        "        \"\"\"\n",
        "        make QCNN for 1 channel only\n",
        "        \"\"\"\n",
        "        input_data = tf.concat([input_data, controller], 1)\n",
        "        QCNN_output = tfq.layers.Expectation()(circuit_inputs,\n",
        "                                               symbol_names=self.params,\n",
        "                                               symbol_values=input_data,\n",
        "                                               operators=self.op)\n",
        "        QCNN_output = tf.reshape(QCNN_output, shape=[-1, self.num_x, self.num_y, self.channel])\n",
        "        return tf.math.reduce_sum(QCNN_output, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRlrNujV0BI6"
      },
      "outputs": [],
      "source": [
        "qcnn_model = Sequential()\n",
        "\n",
        "\n",
        "qcnn_model.add(QConv(filter_size=2, depth=8, activation='relu',name='qconv1', input_shape=(10, 10, 1)))\n",
        "\n",
        "qcnn_model.add(Flatten())\n",
        "qcnn_model.add(Dense(32, activation='relu'))\n",
        "qcnn_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avh57CCn0EhJ",
        "outputId": "57aafa88-75cf-4dbb-fd97-fabf7d3e0208"
      },
      "outputs": [],
      "source": [
        "qcnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "3Sc4Yqhx0PFN",
        "outputId": "b4fc6076-7c69-4987-aa23-7b140500b693"
      },
      "outputs": [],
      "source": [
        "SVGCircuit(QConv(filter_size=2, depth=0, activation='relu').circuit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "kclvHyvk0SmU",
        "outputId": "5adc3e74-40cc-4923-9d84-7894f0aa3341"
      },
      "outputs": [],
      "source": [
        "import pydot\n",
        "import graphviz\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(qcnn_model, to_file='model_shapes.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1x6Agl1oK6W",
        "outputId": "d463342a-c27c-4816-f913-6df89193ebcf"
      },
      "outputs": [],
      "source": [
        "qcnn_model.compile(optimizer=tf.keras.optimizers.Adam(),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "qcnn_history = qcnn_model.fit(x_train, y_train,steps_per_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=10, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mm2zTZw0mgd"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = qcnn_model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8KZ5VQR1Xio"
      },
      "source": [
        "# 4. Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rNIeBd11brR"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "def plot_loss_curves(cnn_loss, qcnn_loss):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(np.arange(len(cnn_loss)) + 1, cnn_loss, \"rs-\", label=\"CNN\")\n",
        "    plt.plot(np.arange(len(qcnn_loss)) + 1, qcnn_loss, \"b^-\", label=\"QCNN\")\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
        "    plt.axis([1, 10, 0, 1])\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Test set loss\")\n",
        "    plt.grid(True)\n",
        "    fig.savefig('loss.png',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yLYoE4E3Bww"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(cnn_history.history['val_loss'], qcnn_history.history['val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxS0eDOJ2RPk"
      },
      "outputs": [],
      "source": [
        "def plot_acc_curves(cnn_acc, qcnn_acc):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(np.arange(len(cnn_acc)) + 1, cnn_acc, \"rs-\", label=\"CNN\")\n",
        "    plt.plot(np.arange(len(qcnn_acc)) + 1, qcnn_acc, \"b^-\", label=\"QCNN\")\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
        "    plt.grid()\n",
        "    plt.axis([1, 50, 0.8, 1])\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Test set accuracy\")\n",
        "    fig.savefig('accuracy.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1m9tAGt24KA"
      },
      "outputs": [],
      "source": [
        "plot_acc_curves(cnn_history.history['val_accuracy'], qcnn_history.history['val_accuracy'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
